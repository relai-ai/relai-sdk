{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5600a6fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ------------------------------------------------------------\n",
    "# Prereqs:\n",
    "#   export RELAI_API_KEY=\"relai-...\"        # your RELAI API key\n",
    "#   export OPENAI_API_KEY=\"sk-...\"          # if your agent/tool uses OpenAI\n",
    "#   export GEMINI_API_KEY=\"AI...\"          # if your agent/tool uses Gemini\n",
    "#   pip install relai                  # relai\n",
    "#\n",
    "# Here we demonstrate with a simple weather bot agent:\n",
    "# How to run agents in a simulated environment.\n",
    "\n",
    "!pip install relai google-genai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ee707b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "os.environ[\"RELAI_API_KEY\"] = \"relai-...\"  # or set permanently in your system\n",
    "os.environ[\"OPENAI_API_KEY\"] = \"sk-...\"  # or set permanently in your system\n",
    "os.environ[\"GEMINI_API_KEY\"] = \"AI...\"  # or set permanently in your system"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "599fb80a",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from google import genai\n",
    "from google.genai import types\n",
    "\n",
    "from relai import (\n",
    "    AgentOutputs,\n",
    "    AsyncRELAI,\n",
    "    AsyncSimulator,\n",
    "    SimulationTape,\n",
    "    random_env_generator,\n",
    ")\n",
    "from relai.mocker import MockTool, Persona\n",
    "from relai.simulator import simulated\n",
    "\n",
    "AGENT_NAME = \"Weather Bot\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d165f04",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# ============================================================================\n",
    "# STEP 1 — Decorate inputs/tools that will be simulated\n",
    "# ============================================================================\n",
    "\n",
    "\n",
    "@simulated\n",
    "async def get_user_query() -> str:\n",
    "    \"\"\"Get user's query about the live weather.\"\"\"\n",
    "    # In a real agent, this function might get input from a chat interface.\n",
    "    # Since we are simulating this function, we return a fixed query.\n",
    "    return \"What's the weather like in Washington DC?\"\n",
    "\n",
    "\n",
    "@simulated\n",
    "def get_current_weather(location: str) -> str:\n",
    "    \"\"\"Returns the current weather.\n",
    "\n",
    "    Args:\n",
    "      location: The city and state, e.g. San Francisco, CA\n",
    "    \"\"\"\n",
    "    # In a real implementation, this function would query an external weather API\n",
    "    # Since we are simulating this tool, we return a fixed weather response.\n",
    "    return \"Sunny\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a108bd2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================================\n",
    "# STEP 2 — Your agent core\n",
    "# ============================================================================\n",
    "\n",
    "\n",
    "async def weatherbot(question: str) -> dict[str, str]:\n",
    "    client = genai.Client()\n",
    "    response = client.models.generate_content(\n",
    "        model=\"gemini-2.5-flash\",\n",
    "        contents=question,\n",
    "        config=types.GenerateContentConfig(tools=[get_current_weather]),\n",
    "    )\n",
    "\n",
    "    return {\"response\": response.text}  # type: ignore"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28d03741",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================================\n",
    "# STEP 3 — Wrap agent for simulation traces\n",
    "# ============================================================================\n",
    "\n",
    "\n",
    "async def agent_fn(tape: SimulationTape) -> AgentOutputs:\n",
    "    question = await get_user_query()\n",
    "    tape.agent_inputs[\"question\"] = question  # trace inputs for later auditing\n",
    "    return await weatherbot(question)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fabbdeab",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================================\n",
    "# STEP 4 — Simulate\n",
    "# ============================================================================\n",
    "\n",
    "\n",
    "async def main() -> None:\n",
    "    # 4.1 — Set up your simulation environment\n",
    "    # Bind Personas/MockTools to fully-qualified function names\n",
    "    env_generator = random_env_generator(\n",
    "        config_set={\n",
    "            \"__main__.get_user_query\": [Persona(user_persona=\"A polite and curious user.\")],\n",
    "            \"__main__.get_current_weather\": [MockTool(model=\"gemini/gemini-2.5-flash\")],\n",
    "        }\n",
    "    )\n",
    "\n",
    "    async with AsyncRELAI() as client:\n",
    "        # 4.2 — SIMULATE\n",
    "        simulator = AsyncSimulator(agent_fn=agent_fn, env_generator=env_generator, client=client)\n",
    "        agent_logs = await simulator.run(num_runs=1)\n",
    "        print(agent_logs)\n",
    "\n",
    "\n",
    "# asyncio.run(main()) # for python\n",
    "await main() # for notebook"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
