<h1>API Reference</h1>

- [Benchmark](benchmark.md): Data abstractions for packaging annotated samples into reusable benchmarks and CSV-backed suites.
- [Critico](critico.md): Orchestrator that aggregates evaluator results and reports back to the RELAI platform.
- [Evaluator](evaluator.md): Base classes and built-in evaluators for rubric, format, style, and annotation scoring.
- [Maestro](maestro.md): Optimization engine that tunes agent configs and structure based on evaluation feedback.
- [Mockers](mockers.md): Persona and mock tool definitions for simulating MCP interactions during tests.
- [Simulator](simulator.md): Decorators and simulator runtimes to replay agent flows in controlled environments.
- [Types](types.md): Core data models (`RELAISample`, `SimulationTape`, logs) shared across simulation and evaluation.
